---
layout: post
title: "Can Reasoning Models Obfuscate Reasoning?"
date: 2025-10-21 12:00:00 -0700
categories: [research]
thumbnail: /images/figure_1_box.jpg
subtitle: "NeurIPS FoRLM workshop. Findings used by Anthropic; cited by OpenAI."
---

We stress-test the monitorability of chain-of-thought reasoning in language models, investigating whether reasoning models can obfuscate their reasoning processes.

[Read the paper on arXiv â†’](https://arxiv.org/abs/2510.19851)

**Paper accepted at NeurIPS 2025 FoRLM workshop.** Findings used by Anthropic in [Claude Opus 4.6 safety evaluations](https://www-cdn.anthropic.com/14e4fb01875d2a69f646fa5e574dea2b1c0ff7b5.pdf#page=143.14) and cited by OpenAI's [Monitoring Monitorability](https://cdn.openai.com/pdf/d57827c6-10bc-47fe-91aa-0fde55bd3901/monitoring-monitorability.pdf) paper.
